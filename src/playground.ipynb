{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"thenlper/gte-large\")\n",
    "\n",
    "# Sentences we want to encode. Example:\n",
    "sentence = \"This framework generates embeddings for each input sentence\"\n",
    "\n",
    "# Sentences are encoded by calling model.encode()\n",
    "embedding = model.encode(sentence, output_value=\"token_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = model.encode(sentence, output_value=\"token_embeddings\")\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = \"payment\"\n",
    "w2 = \"onion\"\n",
    "\n",
    "# Compute the embeddings\n",
    "embedding1 = model.encode(w1, output_value=\"token_embeddings\")\n",
    "embedding2 = model.encode(w2, output_value=\"token_embeddings\")\n",
    "\n",
    "# Compute the cosine-similarity\n",
    "from sentence_transformers import SimilarityFunction\n",
    "\n",
    "cosine_fn = SimilarityFunction.to_similarity_fn(\"cosine\")\n",
    "cosine_score = cosine_fn(embedding1, embedding2)\n",
    "\n",
    "print(\"Cosine-Similarity:\", cosine_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mismayil/.pyenv/versions/3.10.14/envs/cs-gen/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from report_metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Hello world! How are you doing?\"\n",
    "\n",
    "emb1 = get_embedding(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Thank you! I am doing well.\"\n",
    "emb2 = get_embedding(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'of', 'its', 'a', 'house']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = \"In the heart of the enchanted forest stood a sentient house, its windows like eyes observing the world. It longed to live, to experience life beyond its rooted existence. One moonlit night, a shooting star granted its wish, transforming the house into a towering golem of wood and stone. As it roamed the forest, its window-eyes saw wonders and met creatures it had only dreamed of. With each step, the house-turned-golem learned the essence of life, its walls now filled with memories instead of rooms.\"\n",
    "get_words(text3, remove_stopwords=False, dominant_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = compute_sem_dis(emb1, emb2)\n",
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4 = \"As the alien spacecraft hovered silently above the city, its metallic surface gleaming in the moonlight, Dr. Eliza Chen peered anxiously through the observatory's window. Her lifetime of research into extraterrestrial life had led to this moment, but nothing could have prepared her for the sight of the massive vessel, easily the size of a house, descending gracefully towards the Earth. With trembling hands, she reached for the radio transmitter, knowing that her next words could determine whether humanity would live or perish. \\\"Welcome,\\\" she breathed into the microphone, her voice barely above a whisper, \\\"We come in peace.\\\" The ship's response came not in words, but in a brilliant burst of light that bathed the entire planet in a warm, comforting glow.\"\n",
    "compute_theme_uniqueness([text3, text4], cluster_distance_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.023017248541417762, 0.016241591014377388, 0.019932572159316275)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_surprise(text3), compute_surprise(text4), compute_surprise(\"\".join([text3, text4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6213592233009708, 0.9705882352941176, 1.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_n_gram_diversity(text3, max_n_gram=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mismayil/.pyenv/versions/3.10.14/envs/cs-gen/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from report_metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_text1 = \"automation innovation software hardware engineering robotics programming digital network data\"\n",
    "rel_text2 = \"food cooking recipe restaurant chef cuisine ingredient flavor\"\n",
    "unrel_text1 = \"ocean laptop basketball poetry mountain refrigerator zebra guitar democracy candle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_avg_sem_dis(rel_text1), compute_avg_sem_dis(rel_text2), compute_avg_sem_dis(unrel_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20274831851323447, 0.15473486483097076, 0.22474116219414605)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_avg_sem_dis(rel_text1), compute_avg_sem_dis(rel_text2), compute_avg_sem_dis(unrel_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['digital',\n",
       "  'hardware',\n",
       "  'automation',\n",
       "  'network',\n",
       "  'robotic',\n",
       "  'program',\n",
       "  'software',\n",
       "  'engineering',\n",
       "  'innovation',\n",
       "  'datum'],\n",
       " ['flavor',\n",
       "  'recipe',\n",
       "  'chef',\n",
       "  'restaurant',\n",
       "  'cooking',\n",
       "  'ingredient',\n",
       "  'cuisine',\n",
       "  'food'],\n",
       " ['mountain',\n",
       "  'laptop',\n",
       "  'basketball',\n",
       "  'zebra',\n",
       "  'refrigerator',\n",
       "  'guitar',\n",
       "  'democracy',\n",
       "  'ocean',\n",
       "  'candle',\n",
       "  'poetry'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words(rel_text1), get_words(rel_text2), get_words(unrel_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24128174781799316"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb1 = get_embedding(\"democracy\")\n",
    "emb2 = get_embedding(\"candle\")\n",
    "\n",
    "compute_sem_dis(emb1, emb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.5, 0.5, 1.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_theme_uniqueness([rel_text1, rel_text2, rel_text2, unrel_text1], cluster_distance_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_json, write_json, find_files\n",
    "from statistics import mean\n",
    "from metrics import compute_n_gram_diversity\n",
    "\n",
    "data_dir = \"../experiments/reports/pilot/run1_report2/human\"\n",
    "files = find_files(data_dir, \"json\")\n",
    "\n",
    "for results_file in files:\n",
    "    results = read_json(results_file)\n",
    "    if \"data\" in results:\n",
    "        corpus = \"\".join([result[\"output\"] for result in results[\"data\"]])\n",
    "        diversity, freqs = compute_n_gram_diversity(corpus, max_n_gram=5, remove_punct=True)\n",
    "        results[\"metrics\"][\"top_10_n_grams\"] = {}\n",
    "\n",
    "        for i, freq_counter in enumerate(freqs):\n",
    "            results[\"metrics\"][\"top_10_n_grams\"][f\"{i+1}-gram\"] = {\" \".join(freq[0]): freq[1] for freq in freq_counter.most_common(10)}\n",
    "    write_json(results, results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1_gram': {'the': 191,\n",
       "  'a': 177,\n",
       "  'of': 85,\n",
       "  'her': 55,\n",
       "  'it': 48,\n",
       "  'letter': 45,\n",
       "  'she': 43,\n",
       "  'to': 37,\n",
       "  'stamp': 35,\n",
       "  'was': 35},\n",
       " '2_gram': {'the letter': 33,\n",
       "  'of a': 28,\n",
       "  'the old': 23,\n",
       "  'old woman': 21,\n",
       "  'it was': 19,\n",
       "  'pressed the': 17,\n",
       "  'onto the': 16,\n",
       "  'woman her': 15,\n",
       "  'gnarled like': 15,\n",
       "  'like the': 15},\n",
       " '3_gram': {'the old woman': 20,\n",
       "  'old woman her': 15,\n",
       "  'gnarled like the': 15,\n",
       "  'woman her hands': 14,\n",
       "  'her hands gnarled': 14,\n",
       "  'hands gnarled like': 14,\n",
       "  'like the roots': 14,\n",
       "  'the roots of': 14,\n",
       "  'pressed the stamp': 13,\n",
       "  'stamp onto the': 12},\n",
       " '4_gram': {'the old woman her': 14,\n",
       "  'old woman her hands': 14,\n",
       "  'woman her hands gnarled': 14,\n",
       "  'her hands gnarled like': 14,\n",
       "  'hands gnarled like the': 14,\n",
       "  'gnarled like the roots': 14,\n",
       "  'like the roots of': 14,\n",
       "  'the roots of a': 12,\n",
       "  'pressed the stamp onto': 11,\n",
       "  'the stamp onto the': 11},\n",
       " '5_gram': {'old woman her hands gnarled': 14,\n",
       "  'woman her hands gnarled like': 14,\n",
       "  'her hands gnarled like the': 14,\n",
       "  'hands gnarled like the roots': 14,\n",
       "  'gnarled like the roots of': 14,\n",
       "  'the old woman her hands': 13,\n",
       "  'like the roots of a': 12,\n",
       "  'pressed the stamp onto the': 11,\n",
       "  'the roots of a willow': 11,\n",
       "  'carefully pressed the stamp onto': 9}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"metrics\"][\"top_10_n_grams\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv(\"../experiments/reports/pilot/run1_report2/gpt-4/pilot_gpt-4_run1_report2_metrics_global.csv\")\n",
    "\n",
    "df[\"metric_corpus_n_gram_diversity\"] = df[\"metric_corpus_n_gram_diversity\"].apply(lambda x: ast.literal_eval(x))\n",
    "df[\"n_gram\"] = [list(range(1, len(df[\"metric_corpus_n_gram_diversity\"][0])+1)) for _ in range(len(df))]\n",
    "df.explode([\"metric_corpus_n_gram_diversity\", \"n_gram\"]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['stamp-letter-send', 'gloom-payment-exist', 'petrol-diesel-pump',\n",
       "       'organ-empire-comply'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"group_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.23887027285782672,\n",
       " 0.6509456547761552,\n",
       " 0.8587164750957854,\n",
       " 0.9123353293413173,\n",
       " 0.928605654048874]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"metric_corpus_n_gram_diversity\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "claude_data = pd.read_csv(\"../experiments/reports/pilot/run1_report1/claude-3-5-sonnet-20240620/pilot_claude-3-5-sonnet-20240620_run1_report1_metrics.csv\")\n",
    "gemini_data = pd.read_csv(\"../experiments/reports/pilot/run1_report1/gemini-1.5-flash/pilot_gemini-1.5-flash_run1_report1_metrics.csv\")\n",
    "gpt4_data = pd.read_csv(\"../experiments/reports/pilot/run1_report1/gpt-4/pilot_gpt-4_run1_report1_metrics.csv\")\n",
    "human_data = pd.read_csv(\"../experiments/reports/pilot/run1_report1/human/pilot_human_run1_report1_metrics.csv\")\n",
    "\n",
    "claude_data[\"model\"] = \"claude\"\n",
    "gemini_data[\"model\"] = \"gemini\"\n",
    "gpt4_data[\"model\"] = \"gpt-4\"\n",
    "human_data[\"model\"] = \"human\"\n",
    "\n",
    "data = pd.concat([claude_data, gemini_data, gpt4_data, human_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file)\n\u001b[1;32m     14\u001b[0m     metric_lst\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mplot_metrics_n_gram_diversity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric_lst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfigures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/phd/projects/project-CSG/creative-story-gen/src/plot_metrics.py:57\u001b[0m, in \u001b[0;36mplot_metrics_n_gram_diversity\u001b[0;34m(metrics_lst, output_dir, output_format)\u001b[0m\n\u001b[1;32m     55\u001b[0m group_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_corpus_n_gram_diversity\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m group_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_corpus_n_gram_diversity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: ast\u001b[38;5;241m.\u001b[39mliteral_eval(x))\n\u001b[1;32m     56\u001b[0m group_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_gram\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(group_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_corpus_n_gram_diversity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(group_metrics))]\n\u001b[0;32m---> 57\u001b[0m group_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mgroup_metrics\u001b[49m\u001b[38;5;241m.\u001b[39mexplode([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_corpus_n_gram_diversity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_gram\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     59\u001b[0m metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_corpus_n_gram_diversity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39mFIG_SIZE)\n",
      "File \u001b[0;32m~/Desktop/phd/projects/project-CSG/creative-story-gen/src/plot_metrics.py:57\u001b[0m, in \u001b[0;36mplot_metrics_n_gram_diversity\u001b[0;34m(metrics_lst, output_dir, output_format)\u001b[0m\n\u001b[1;32m     55\u001b[0m group_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_corpus_n_gram_diversity\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m group_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_corpus_n_gram_diversity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: ast\u001b[38;5;241m.\u001b[39mliteral_eval(x))\n\u001b[1;32m     56\u001b[0m group_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_gram\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(group_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_corpus_n_gram_diversity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(group_metrics))]\n\u001b[0;32m---> 57\u001b[0m group_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mgroup_metrics\u001b[49m\u001b[38;5;241m.\u001b[39mexplode([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_corpus_n_gram_diversity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_gram\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     59\u001b[0m metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_corpus_n_gram_diversity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39mFIG_SIZE)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/cs-gen/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:1197\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_line:\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_suspend(thread, step_cmd, original_step_cmd\u001b[38;5;241m=\u001b[39minfo\u001b[38;5;241m.\u001b[39mpydev_original_step_cmd)\n\u001b[0;32m-> 1197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_return:  \u001b[38;5;66;03m# return event\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m     back \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mf_back\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/cs-gen/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/cs-gen/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/cs-gen/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from plot_metrics import plot_metrics_n_gram_diversity\n",
    "\n",
    "report_name = \"run1_report2\"\n",
    "files = [f\"../experiments/reports/pilot/{report_name}/gpt-4/pilot_gpt-4_{report_name}_metrics_global.csv\",\n",
    "         f\"../experiments/reports/pilot/{report_name}/gemini-1.5-flash/pilot_gemini-1.5-flash_{report_name}_metrics_global.csv\",\n",
    "         f\"../experiments/reports/pilot/{report_name}/claude-3-5-sonnet-20240620/pilot_claude-3-5-sonnet-20240620_{report_name}_metrics_global.csv\",\n",
    "         f\"../experiments/reports/pilot/{report_name}/human/pilot_human_{report_name}_metrics_global.csv\"]\n",
    "\n",
    "metric_lst = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    metric_lst.append(df)\n",
    "\n",
    "plot_metrics_n_gram_diversity(metric_lst, \"figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>metric_num_samples</th>\n",
       "      <th>metric_avg_length_in_chars</th>\n",
       "      <th>metric_avg_length_in_words</th>\n",
       "      <th>metric_avg_length_in_unique_words</th>\n",
       "      <th>metric_avg_length_in_concepts</th>\n",
       "      <th>metric_avg_length_in_sentences</th>\n",
       "      <th>metric_avg_word_length_in_chars</th>\n",
       "      <th>metric_avg_sentence_length_in_chars</th>\n",
       "      <th>...</th>\n",
       "      <th>metric_avg_surprise</th>\n",
       "      <th>metric_avg_n_gram_diversity</th>\n",
       "      <th>metric_avg_inv_homogen</th>\n",
       "      <th>metric_avg_novelty</th>\n",
       "      <th>metric_avg_theme_uniqueness</th>\n",
       "      <th>metric_corpus_dsi</th>\n",
       "      <th>metric_corpus_n_gram_diversity</th>\n",
       "      <th>metric_num_unique_stories</th>\n",
       "      <th>metric_usage</th>\n",
       "      <th>metric_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stamp-letter-send</td>\n",
       "      <td>human</td>\n",
       "      <td>25</td>\n",
       "      <td>376.92</td>\n",
       "      <td>71.96</td>\n",
       "      <td>51.68</td>\n",
       "      <td>26.52</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.093020</td>\n",
       "      <td>92.626571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>[0.6915104836448943, 0.956038259585784, 0.9929...</td>\n",
       "      <td>0.175739</td>\n",
       "      <td>0.015201</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.210958</td>\n",
       "      <td>[0.335, 0.8149074537268635, 0.9734734734734735...</td>\n",
       "      <td>25</td>\n",
       "      <td>{'input_tokens': 0, 'output_tokens': 0, 'total...</td>\n",
       "      <td>{'input': 0, 'output': 0, 'total': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gloom-payment-exist</td>\n",
       "      <td>human</td>\n",
       "      <td>25</td>\n",
       "      <td>341.84</td>\n",
       "      <td>64.92</td>\n",
       "      <td>48.64</td>\n",
       "      <td>25.52</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.161530</td>\n",
       "      <td>92.058667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043166</td>\n",
       "      <td>[0.7206884850969, 0.9676567310683905, 0.993824...</td>\n",
       "      <td>0.179796</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.213749</td>\n",
       "      <td>[0.35797665369649806, 0.8348164627363738, 0.97...</td>\n",
       "      <td>25</td>\n",
       "      <td>{'input_tokens': 0, 'output_tokens': 0, 'total...</td>\n",
       "      <td>{'input': 0, 'output': 0, 'total': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>petrol-diesel-pump</td>\n",
       "      <td>human</td>\n",
       "      <td>25</td>\n",
       "      <td>452.24</td>\n",
       "      <td>85.84</td>\n",
       "      <td>60.96</td>\n",
       "      <td>33.28</td>\n",
       "      <td>5.16</td>\n",
       "      <td>4.180437</td>\n",
       "      <td>91.502571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030483</td>\n",
       "      <td>[0.6815274535500768, 0.9649025007385326, 0.994...</td>\n",
       "      <td>0.155943</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.213922</td>\n",
       "      <td>[0.3210239194292908, 0.8194794290512175, 0.971...</td>\n",
       "      <td>25</td>\n",
       "      <td>{'input_tokens': 0, 'output_tokens': 0, 'total...</td>\n",
       "      <td>{'input': 0, 'output': 0, 'total': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>organ-empire-comply</td>\n",
       "      <td>human</td>\n",
       "      <td>25</td>\n",
       "      <td>364.60</td>\n",
       "      <td>67.92</td>\n",
       "      <td>50.60</td>\n",
       "      <td>26.44</td>\n",
       "      <td>3.84</td>\n",
       "      <td>4.286189</td>\n",
       "      <td>96.552000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021366</td>\n",
       "      <td>[0.7246199155205226, 0.967924976474475, 0.9940...</td>\n",
       "      <td>0.188341</td>\n",
       "      <td>0.006142</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.214997</td>\n",
       "      <td>[0.3532258064516129, 0.8262506724045185, 0.969...</td>\n",
       "      <td>25</td>\n",
       "      <td>{'input_tokens': 0, 'output_tokens': 0, 'total...</td>\n",
       "      <td>{'input': 0, 'output': 0, 'total': 0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              group_id model_id  metric_num_samples  \\\n",
       "0    stamp-letter-send    human                  25   \n",
       "1  gloom-payment-exist    human                  25   \n",
       "2   petrol-diesel-pump    human                  25   \n",
       "3  organ-empire-comply    human                  25   \n",
       "\n",
       "   metric_avg_length_in_chars  metric_avg_length_in_words  \\\n",
       "0                      376.92                       71.96   \n",
       "1                      341.84                       64.92   \n",
       "2                      452.24                       85.84   \n",
       "3                      364.60                       67.92   \n",
       "\n",
       "   metric_avg_length_in_unique_words  metric_avg_length_in_concepts  \\\n",
       "0                              51.68                          26.52   \n",
       "1                              48.64                          25.52   \n",
       "2                              60.96                          33.28   \n",
       "3                              50.60                          26.44   \n",
       "\n",
       "   metric_avg_length_in_sentences  metric_avg_word_length_in_chars  \\\n",
       "0                            4.36                         4.093020   \n",
       "1                            4.00                         4.161530   \n",
       "2                            5.16                         4.180437   \n",
       "3                            3.84                         4.286189   \n",
       "\n",
       "   metric_avg_sentence_length_in_chars  ...  metric_avg_surprise  \\\n",
       "0                            92.626571  ...             0.042553   \n",
       "1                            92.058667  ...             0.043166   \n",
       "2                            91.502571  ...             0.030483   \n",
       "3                            96.552000  ...             0.021366   \n",
       "\n",
       "                         metric_avg_n_gram_diversity  metric_avg_inv_homogen  \\\n",
       "0  [0.6915104836448943, 0.956038259585784, 0.9929...                0.175739   \n",
       "1  [0.7206884850969, 0.9676567310683905, 0.993824...                0.179796   \n",
       "2  [0.6815274535500768, 0.9649025007385326, 0.994...                0.155943   \n",
       "3  [0.7246199155205226, 0.967924976474475, 0.9940...                0.188341   \n",
       "\n",
       "   metric_avg_novelty metric_avg_theme_uniqueness  metric_corpus_dsi  \\\n",
       "0            0.015201                        0.84           0.210958   \n",
       "1            0.010896                        0.96           0.213749   \n",
       "2            0.009814                        0.68           0.213922   \n",
       "3            0.006142                        0.80           0.214997   \n",
       "\n",
       "                      metric_corpus_n_gram_diversity  \\\n",
       "0  [0.335, 0.8149074537268635, 0.9734734734734735...   \n",
       "1  [0.35797665369649806, 0.8348164627363738, 0.97...   \n",
       "2  [0.3210239194292908, 0.8194794290512175, 0.971...   \n",
       "3  [0.3532258064516129, 0.8262506724045185, 0.969...   \n",
       "\n",
       "   metric_num_unique_stories  \\\n",
       "0                         25   \n",
       "1                         25   \n",
       "2                         25   \n",
       "3                         25   \n",
       "\n",
       "                                        metric_usage  \\\n",
       "0  {'input_tokens': 0, 'output_tokens': 0, 'total...   \n",
       "1  {'input_tokens': 0, 'output_tokens': 0, 'total...   \n",
       "2  {'input_tokens': 0, 'output_tokens': 0, 'total...   \n",
       "3  {'input_tokens': 0, 'output_tokens': 0, 'total...   \n",
       "\n",
       "                             metric_cost  \n",
       "0  {'input': 0, 'output': 0, 'total': 0}  \n",
       "1  {'input': 0, 'output': 0, 'total': 0}  \n",
       "2  {'input': 0, 'output': 0, 'total': 0}  \n",
       "3  {'input': 0, 'output': 0, 'total': 0}  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../experiments/reports/pilot/run1_report2/human/pilot_human_run1_report2_metrics_global.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs-gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
